{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè• Breast Cancer Detection - Transfer Learning Training\n",
                "Ce notebook utilise le **Transfer Learning (VGG16)** pour la d√©tection du cancer du sein.\n",
                "\n",
                "### üöÄ Strat√©gie :\n",
                "1.  **Phase 1 (Warmup)** : On g√®le le corps du mod√®le VGG16 et on entra√Æne uniquement les nouvelles couches finales.\n",
                "2.  **Phase 2 (Fine-tuning)** : On d√©bloque les couches de VGG16 pour affiner la pr√©cision avec un taux d'apprentissage tr√®s faible."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üõ†Ô∏è 1. Installation et Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import json\n",
                "import random\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "from PIL import Image\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import (\n",
                "    classification_report,\n",
                "    confusion_matrix,\n",
                "    roc_curve,\n",
                "    auc,\n",
                "    precision_recall_curve\n",
                ")\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "print(f\"TensorFlow version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öôÔ∏è 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n",
                "    'data': {\n",
                "        'raw_input': 'data/raw',\n",
                "        'cleaned_output': 'data/cleaned',\n",
                "        'train_dir': 'data/cleaned/train',\n",
                "        'val_dir': 'data/cleaned/val',\n",
                "        'test_dir': 'data/cleaned/test'\n",
                "    },\n",
                "    'model': {\n",
                "        'img_size': 128,\n",
                "        'base_model': 'VGG16',\n",
                "        'fine_tune_epochs': 15\n",
                "    },\n",
                "    'training': {\n",
                "        'batch_size': 32,\n",
                "        'epochs': 30,\n",
                "        'learning_rate': 0.0001\n",
                "    }\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üßπ 3. Preprocessing\n",
                "Uploadez vos dossiers `Positive` et `Negative` dans `data/raw/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def validate_and_clean_image(image_path, target_size=(128, 128)):\n",
                "    try:\n",
                "        img = Image.open(image_path)\n",
                "        img = img.convert(\"RGB\")\n",
                "        img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
                "        return img\n",
                "    except Exception as e:\n",
                "        return None\n",
                "\n",
                "def prepare_dataset(input_dir, output_dir, target_size=(128, 128), split_ratios=(0.7, 0.15, 0.15)):\n",
                "    input_path = Path(input_dir)\n",
                "    output_path = Path(output_dir)\n",
                "    for split in ['train', 'val', 'test']:\n",
                "        for cls in ['Positive', 'Negative']:\n",
                "            (output_path / split / cls).mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    for cls in ['Positive', 'Negative']:\n",
                "        cls_dir = input_path / cls\n",
                "        if not cls_dir.exists(): continue\n",
                "        images = [f for f in cls_dir.glob('*') if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
                "        random.shuffle(images)\n",
                "        n = len(images)\n",
                "        n_train = int(n * split_ratios[0])\n",
                "        n_val = int(n * split_ratios[1])\n",
                "        \n",
                "        splits = {'train': images[:n_train], 'val': images[n_train:n_train + n_val], 'test': images[n_train + n_val:]}\n",
                "        for split, split_images in splits.items():\n",
                "            for img_p in split_images:\n",
                "                cleaned_img = validate_and_clean_image(img_p, target_size)\n",
                "                if cleaned_img:\n",
                "                    cleaned_img.save(output_path / split / cls / f\\\"{img_p.stem}.jpg\\\", \\\"JPEG\\\", quality=95)\n",
                "\n",
                "# Init folders\n",
                "for d in ['data/raw/Positive', 'data/raw/Negative']: Path(d).mkdir(parents=True, exist_ok=True)\n",
                "print(\"üöÄ Dossiers pr√™ts.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèóÔ∏è 4. Mod√®le (Transfer Learning)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_tl_model(input_shape=(128, 128, 3)):\n",
                "    base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
                "    base_model.trainable = False  # On commence par geler le corps\n",
                "    \n",
                "    model = keras.Sequential([\n",
                "        base_model,\n",
                "        layers.GlobalAveragePooling2D(),\n",
                "        layers.Dense(256, activation='relu'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Dropout(0.5),\n",
                "        layers.Dense(1, activation='sigmoid')\n",
                "    ])\n",
                "    return model, base_model\n",
                "\n",
                "model, base_model = build_tl_model()\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèãÔ∏è 5. Entra√Ænement en deux phases"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prepare_dataset(CONFIG['data']['raw_input'], CONFIG['data']['cleaned_output'])\n",
                "img_size = CONFIG['model']['img_size']\n",
                "\n",
                "def get_ds(path): \n",
                "    ds = keras.preprocessing.image_dataset_from_directory(path, image_size=(img_size, img_size), label_mode='binary', batch_size=32)\n",
                "    return ds.map(lambda x, y: (layers.Rescaling(1./255)(x), y)).cache().prefetch(tf.data.AUTOTUNE)\n",
                "\n",
                "train_ds = get_ds(CONFIG['data']['train_dir'])\n",
                "val_ds = get_ds(CONFIG['data']['val_dir'])\n",
                "test_ds = get_ds(CONFIG['data']['test_dir'])\n",
                "\n",
                "model.compile(optimizer=keras.optimizers.Adam(learning_rate=CONFIG['training']['learning_rate']),\n",
                "              loss='binary_crossentropy', metrics=['accuracy', keras.metrics.AUC(name='auc')])\n",
                "\n",
                "print(\"\\nüî• Phase 1 : Entra√Ænement des couches denses...\")\n",
                "model.fit(train_ds, validation_data=val_ds, epochs=CONFIG['training']['epochs'])\n",
                "\n",
                "print(\"\\n‚ùÑÔ∏è  Phase 2 : Fine-tuning (on d√©g√®le VGG16)...\")\n",
                "base_model.trainable = True\n",
                "model.compile(optimizer=keras.optimizers.Adam(learning_rate=CONFIG['training']['learning_rate'] / 10),\n",
                "              loss='binary_crossentropy', metrics=['accuracy', keras.metrics.AUC(name='auc')])\n",
                "model.fit(train_ds, validation_data=val_ds, epochs=CONFIG['model']['fine_tune_epochs'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä 6. √âvaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_true, y_pred_proba = [], []\n",
                "for images, labels in test_ds:\n",
                "    y_true.extend(labels.numpy())\n",
                "    y_pred_proba.extend(model.predict(images, verbose=0).flatten())\n",
                "\n",
                "y_pred = (np.array(y_pred_proba) > 0.5).astype(int)\n",
                "print(classification_report(y_true, y_pred, target_names=['Negative', 'Positive']))\n",
                "model.save('final_model_transfer_learning.h5')\n",
                "print(\"‚úÖ Mod√®le sauvegard√© !\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}