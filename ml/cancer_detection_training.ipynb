{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè• Breast Cancer Detection - Transfer Learning (DenseNet121)\n",
                "Ce notebook utilise l'architecture **DenseNet121**, reconnue pour ses performances sup√©rieures en imagerie m√©dicale.\n",
                "\n",
                "### üöÄ Strat√©gie :\n",
                "1.  **Phase 1 (Warmup)** : On g√®le le corps du mod√®le DenseNet121 et on entra√Æne les couches finales.\n",
                "2.  **Phase 2 (Fine-tuning)** : On d√©bloque toutes les couches pour affiner la d√©tection des micro-d√©tails mammographiques."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üõ†Ô∏è 1. Installation et Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import json\n",
                "import random\n",
                "from pathlib import Path\n",
                "from PIL import Image\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "print(f\"TensorFlow version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚öôÔ∏è 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n",
                "    'data': {\n",
                "        'raw_input': 'data/raw',\n",
                "        'cleaned_output': 'data/cleaned',\n",
                "        'train_dir': 'data/cleaned/train',\n",
                "        'val_dir': 'data/cleaned/val',\n",
                "        'test_dir': 'data/cleaned/test'\n",
                "    },\n",
                "    'model': {\n",
                "        'img_size': 128,\n",
                "        'base_model': 'DenseNet121',\n",
                "        'fine_tune_epochs': 15\n",
                "    },\n",
                "    'training': {\n",
                "        'batch_size': 32,\n",
                "        'epochs': 30,\n",
                "        'learning_rate': 0.0001\n",
                "    }\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üßπ 3. Preprocessing\n",
                "Uploadez vos dossiers `Positive` et `Negative` dans `data/raw/` dans la barre lat√©rale gauche."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def validate_and_clean_image(image_path, target_size=(128, 128)):\n",
                "    try:\n",
                "        img = Image.open(image_path)\n",
                "        img = img.convert(\"RGB\")\n",
                "        img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
                "        return img\n",
                "    except: return None\n",
                "\n",
                "def prepare_dataset(input_dir, output_dir, target_size=(128, 128), split_ratios=(0.7, 0.15, 0.15)):\n",
                "    input_path, output_path = Path(input_dir), Path(output_dir)\n",
                "    for split in ['train', 'val', 'test']:\n",
                "        for cls in ['Positive', 'Negative']: (output_path / split / cls).mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    for cls in ['Positive', 'Negative']:\n",
                "        cls_dir = input_path / cls\n",
                "        if not cls_dir.exists(): continue\n",
                "        images = [f for f in cls_dir.glob('*') if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
                "        random.shuffle(images)\n",
                "        n = len(images); n1 = int(n * split_ratios[0]); n2 = int(n * (split_ratios[0]+split_ratios[1]))\n",
                "        \n",
                "        splits = {'train': images[:n1], 'val': images[n1:n2], 'test': images[n2:]}\n",
                "        for s_name, s_imgs in splits.items():\n",
                "            print(f\"Processing {s_name}/{cls}...\")\n",
                "            for img_p in s_imgs:\n",
                "                c_img = validate_and_clean_image(img_p, target_size)\n",
                "                if c_img: c_img.save(output_path / s_name / cls / f\\\"{img_p.stem}.jpg\\\", \\\"JPEG\\\")\n",
                "\n",
                "for d in ['data/raw/Positive', 'data/raw/Negative']: Path(d).mkdir(parents=True, exist_ok=True)\n",
                "print(\"üöÄ Dossiers initialis√©s.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèóÔ∏è 4. Mod√®le (Transfer Learning DenseNet121)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_densenet_model(input_shape=(128, 128, 3)):\n",
                "    base_model = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
                "    base_model.trainable = False\n",
                "    \n",
                "    model = keras.Sequential([\n",
                "        base_model,\n",
                "        layers.GlobalAveragePooling2D(),\n",
                "        layers.Dense(256, activation='relu'),\n",
                "        layers.BatchNormalization(),\n",
                "        layers.Dropout(0.5),\n",
                "        layers.Dense(1, activation='sigmoid')\n",
                "    ])\n",
                "    return model, base_model\n",
                "\n",
                "model, base_model = build_densenet_model()\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèãÔ∏è 5. Entra√Ænement"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prepare_dataset(CONFIG['data']['raw_input'], CONFIG['data']['cleaned_output'])\n",
                "img_size = CONFIG['model']['img_size']\n",
                "\n",
                "def get_ds(path): \n",
                "    ds = keras.preprocessing.image_dataset_from_directory(path, image_size=(img_size, img_size), label_mode='binary', batch_size=32)\n",
                "    return ds.map(lambda x, y: (layers.Rescaling(1./255)(x), y)).cache().prefetch(tf.data.AUTOTUNE)\n",
                "\n",
                "train_ds = get_ds(CONFIG['data']['train_dir'])\n",
                "val_ds = get_ds(CONFIG['data']['val_dir'])\n",
                "test_ds = get_ds(CONFIG['data']['test_dir'])\n",
                "\n",
                "model.compile(optimizer=keras.optimizers.Adam(learning_rate=CONFIG['training']['learning_rate']),\n",
                "              loss='binary_crossentropy', metrics=['accuracy'])\n",
                "\n",
                "print(\"\\nüî• Phase 1 : Entra√Ænement Initial...\")\n",
                "model.fit(train_ds, validation_data=val_ds, epochs=CONFIG['training']['epochs'])\n",
                "\n",
                "print(\"\\n‚ùÑÔ∏è  Phase 2 : Fine-tuning...\")\n",
                "base_model.trainable = True\n",
                "model.compile(optimizer=keras.optimizers.Adam(learning_rate=CONFIG['training']['learning_rate'] / 10),\n",
                "              loss='binary_crossentropy', metrics=['accuracy'])\n",
                "model.fit(train_ds, validation_data=val_ds, epochs=CONFIG['model']['fine_tune_epochs'])\n",
                "\n",
                "model.save('model_breast_cancer_densenet.h5')\n",
                "print(\"‚úÖ Mod√®le final sauvegard√© !\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}